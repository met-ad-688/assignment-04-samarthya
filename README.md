# Assignment 04 - Salary Prediction with PySpark

## ğŸ“‹ Project Overview

This project implements a comprehensive salary prediction machine learning pipeline using PySpark and the Lightcast job postings dataset. The analysis compares three different regression models to predict job salaries based on various features.

## ğŸ¯ Objectives

- **Data Processing**: Use PySpark to process large-scale Lightcast dataset (11.9M rows, 131 columns)
- **Feature Engineering**: Engineer features from structured columns for salary prediction
- **Model Training**: Train and evaluate Linear Regression, Polynomial Regression, and Random Forest models
- **Model Evaluation**: Assess models using RMSE, RÂ², and MAE metrics
- **Visualization**: Create diagnostic plots for model interpretation

## ğŸ“Š Dataset

- **Source**: Lightcast job postings dataset
- **Size**: 684MB, 11,992,060 rows Ã— 131 columns
- **Target Variable**: SALARY
- **Features Selected**: 10 variables including 3 continuous, 2 categorical, and additional engineered features

## ğŸ”§ Technical Implementation

### Selected Features

1. **Continuous Variables (3)**:
   - MIN_YEARS_EXPERIENCE
   - MAX_YEARS_EXPERIENCE  
   - DURATION

2. **Categorical Variables (2)**:
   - EMPLOYMENT_TYPE_NAME
   - REMOTE_TYPE_NAME

3. **Additional Features (5)**:
   - EDUCATION_LEVELS_NAME (categorical)
   - STATE_NAME (categorical)
   - IS_INTERNSHIP (binary)
   - COMPANY_IS_STAFFING (binary)
   - MIN_EDULEVELS (ordinal)

4. **Engineered Features**:

   - MIN_YEARS_EXPERIENCE_SQ (polynomial feature)

### Data Preprocessing Pipeline

- **StringIndexer**: Convert categorical variables to numerical indices
- **OneHotEncoder**: Create binary vectors for categorical variables
- **VectorAssembler**: Combine all features into feature vectors
- **Data Split**: 80/20 train-test split with random seed 42

### Models Implemented

1. **Linear Regression**: Baseline interpretable model
2. **Polynomial Linear Regression**: Enhanced with squared experience term
3. **Random Forest Regressor**: Ensemble method (300 trees, max depth 6)

## ğŸ“ Project Structure

```bash
assignment-04-samarthya/
â”œâ”€â”€ salary_prediction_analysis.ipynb    # Main analysis notebook
â”œâ”€â”€ data/
â”‚   â””â”€â”€ lightcast_job_postings.csv     # Dataset (684MB)
â”œâ”€â”€ output/                             # Output directory
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ README.md                          # Project documentation
â””â”€â”€ .gitignore                         # Git ignore file
```

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- Java 8+ (for PySpark)
- Virtual environment recommended

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/met-ad-688/assignment-04-samarthya.git
   cd assignment-04-samarthya
   ```

2. Create and activate virtual environment:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Launch Jupyter:

   ```bash
   jupyter notebook salary_prediction_analysis.ipynb
   ```

## ğŸ” Analysis Highlights

### Feature Engineering

- Created polynomial features to capture non-linear relationships
- Implemented comprehensive preprocessing pipeline
- Handled missing values and categorical encoding

### Model Evaluation

- Comprehensive comparison using multiple metrics
- Statistical significance testing for linear models
- Feature importance analysis for Random Forest
- Diagnostic plots for residual analysis

### Business Insights

- Identification of key salary predictors
- Feature importance for compensation strategy
- Model recommendations for production deployment

## ğŸ› ï¸ Technologies Used

- **PySpark 4.0.1**: Distributed data processing and machine learning
- **Python**: Data analysis and visualization
- **Jupyter Notebook**: Interactive development environment
- **Matplotlib/Seaborn**: Data visualization
- **Pandas**: Data manipulation and analysis

## ğŸ“‹ Assignment Requirements Fulfilled

âœ… **Data Processing**: PySpark implementation for large dataset  
âœ… **Feature Selection**: 10 variables (3 continuous, 2 categorical)  
âœ… **Feature Engineering**: Polynomial features and preprocessing pipeline  
âœ… **Model Training**: Linear Regression, Polynomial Regression, Random Forest  
âœ… **Model Evaluation**: RMSE, RÂ², MAE metrics with statistical analysis  
âœ… **Visualization**: Diagnostic plots and model comparison  
âœ… **Documentation**: Comprehensive notebook with interpretations  

## ğŸ”— Repository

- **GitHub**: [https://github.com/met-ad-688/assignment-04-samarthya](https://github.com/met-ad-688/assignment-04-samarthya)
- **Jupyter Notebook**: `salary_prediction_analysis.ipynb`

## ğŸ‘¨â€ğŸ’» Author

**Samarthya**  
Course: MET AD 688  
Assignment: 04 - Salary Prediction with PySpark

## ğŸ“ License

This project is for educational purposes as part of MET AD 688 coursework.

---

**Note**: Run all cells in the Jupyter notebook sequentially to reproduce the complete analysis. The notebook includes detailed explanations, code comments, and interpretations for each step of the machine learning pipeline.
